{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/88/7640344d841e97b9a1531385caac39d984b2c6f4abd1376e1ce0de3a0933/torch-1.2.0-cp37-none-macosx_10_7_x86_64.whl (59.9MB)\n",
      "\u001b[K     |████████████████████████████████| 59.9MB 201kB/s eta 0:00:01    |████▌                           | 8.3MB 410kB/s eta 0:02:06     |█████▋                          | 10.6MB 396kB/s eta 0:02:05     |██████████████▏                 | 26.5MB 522kB/s eta 0:01:04     |████████████████████▎           | 38.0MB 290kB/s eta 0:01:16\n",
      "\u001b[?25hRequirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from torch) (1.16.4)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/9d/01afb6f6eccde291df2ec254eab7947cd9251cd02d4fac2968fd49e8af73/torchvision-0.4.0-cp37-cp37m-macosx_10_7_x86_64.whl (582kB)\n",
      "\u001b[K     |████████████████████████████████| 583kB 345kB/s eta 0:00:01    |█▊                              | 30kB 299kB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /anaconda3/lib/python3.7/site-packages (from torchvision) (6.1.0)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: torch==1.2.0 in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.2.0)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from torchvision) (1.16.4)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the version of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "\n",
    "LINK - https://pytorch.org/docs/stable/torchvision/index.html\n",
    "\n",
    "Preprocessing of data such as conversion of the features into Tensors and Normalisation is done when we load the data. \n",
    "\n",
    "Transforms are common image transformations. They can be chained together using Compose.\n",
    "\n",
    "Here we are applying two types of transforms to the images in the dataset.\n",
    "\n",
    "1. Converting the images in to torch tensors\n",
    "2. Normalising the images using mean and standard deviation\n",
    "\n",
    "(x_normalized = x-mean / std\n",
    "\n",
    "The values 0.1307 and 0.3081 represent the mean and standard deviation for MNIST dataset)\n",
    "\n",
    "LINK - https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "Dataset can we downloaded using the inbuilt function in pytorch \n",
    "\n",
    "LINK - https://pytorch.org/docs/stable/torchvision/datasets.html#mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bhuvanaka/pytorch-tutorial'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9854976/9912422 [01:13<00:00, 11087316.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:02<?, ?it/s]\u001b[A\n",
      "32768it [00:02, 12115.34it/s]            \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [01:30, 11087316.05it/s]                             \n",
      "  0%|          | 0/1648877 [00:14<?, ?it/s]\u001b[A\n",
      " 34%|███▍      | 557056/1648877 [00:14<00:00, 5563031.75it/s]\u001b[A\n",
      " 91%|█████████ | 1499136/1648877 [00:15<00:00, 6329730.67it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 9651.33it/s]             \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#transforming the images to tensors and normalising\n",
    "transforms = transforms.Compose(([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "# mnist train_set\n",
    "mnist_train = MNIST('./data',train=True,download=True,transform=transforms)\n",
    "\n",
    "# mnist test_set\n",
    "mnist_test = MNIST('./data',train=False,transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a train test and validation set. \n",
    "\n",
    "Train Dataset:\n",
    "The actual dataset that we use to train the model (weights and biases in the case of Neural Network). The model sees and learns from this data.\n",
    "\n",
    "Validation Dataset:\n",
    "The validation set is used to evaluate a given model, but this is for frequent evaluation. We as machine learning engineers use this data to fine-tune the model hyperparameters. Hence the model occasionally sees this data, but never does it “Learn” from this.\n",
    "\n",
    "Test Dataset:\n",
    "The Test dataset provides the gold standard used to evaluate the model. It is only used once a model is completely trained(using the train and validation sets). The test set is generally what is used to evaluate competing models.\n",
    "\n",
    "We split the training dataset into Train and Validation dataset. Here we will split 90% of our training data into train dataset and 10% into validation dataset.\n",
    "\n",
    "We would be using torch.utils.data.random_split function to randomly split the training data.\n",
    "\n",
    "LINK - https://pytorch.org/docs/stable/data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.9*mnist_train.__len__())\n",
    "valid_len = mnist_train.__len__() - train_len\n",
    "mnist_train, mnist_valid = torch.utils.data.random_split(mnist_train, lengths=[train_len, valid_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of : Training-set:\t\t54000\n",
      "Size of : Validation-set:\t6000\n",
      "Size of : Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of : Training-set:\\t\\t{mnist_train.__len__()}\") \n",
    "print(f\"Size of : Validation-set:\\t{mnist_valid.__len__()}\") \n",
    "print(f\"Size of : Test-set:\\t\\t{mnist_test.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 784 # 28 x 28\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (28,28)\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper-function for plotting images\n",
    "\n",
    "Function used to plot 9 images in a 3x3 grid, and writing the true and predicted classes below each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a few images to see if data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = mnist_test.data[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = mnist_test.targets[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "PyTorch is a Python package that provides two high-level features:\n",
    "\n",
    "1. Tensor computation (like NumPy) with strong GPU acceleration\n",
    "2. Deep neural networks built on a tape-based autograd system\n",
    "\n",
    "You can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed.\n",
    "\n",
    "## More about PyTorch\n",
    "\n",
    "At a granular level, PyTorch is a library that consists of the following components:\n",
    "\n",
    "| Component | Description |\n",
    "| ---- | --- |\n",
    "| **torch** | a Tensor library like NumPy, with strong GPU support |\n",
    "| **torch.autograd** | a tape-based automatic differentiation library that supports all differentiable Tensor operations in torch |\n",
    "| **torch.nn** | a neural networks library deeply integrated with autograd designed for maximum flexibility |\n",
    "| **torch.multiprocessing** | Python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and Hogwild training |\n",
    "| **torch.utils** | DataLoader, Trainer and other utility functions for convenience |\n",
    "| **torch.legacy(.nn/.optim)** | legacy code that has been ported over from torch for backward compatibility reasons |\n",
    "\n",
    "Usually one uses PyTorch either as:\n",
    "\n",
    "- a replacement for NumPy to use the power of GPUs.\n",
    "- a deep learning research platform that provides maximum flexibility and speed\n",
    "\n",
    "### Dynamic Neural Networks: Tape-Based Autograd\n",
    "\n",
    "PyTorch has a unique way of building neural networks: using and replaying a tape recorder.\n",
    "\n",
    "Most frameworks such as TensorFlow, Theano, Caffe and CNTK have a static view of the world.\n",
    "One has to build a neural network, and reuse the same structure again and again.\n",
    "Changing the way the network behaves means that one has to start from scratch.\n",
    "\n",
    "With PyTorch, we use a technique called reverse-mode auto-differentiation, which allows you to\n",
    "change the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes\n",
    "from several research papers on this topic, as well as current and past work such as\n",
    "[torch-autograd](https://github.com/twitter/torch-autograd),\n",
    "[autograd](https://github.com/HIPS/autograd),\n",
    "[Chainer](http://chainer.org), etc.\n",
    "\n",
    "While this technique is not unique to PyTorch, it's one of the fastest implementations of it to date.\n",
    "You get the best of speed and flexibility for your crazy research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Reading\n",
    "https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can be constructed using the torch.nn package.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "- Define the neural network that has some learnable parameters (or weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the network’s parameters\n",
    "- Update the weights of the network, typically using a simple update rule:    \n",
    "`weight = weight - learning_rate * gradient`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define networks as a subclass of nn.Module\n",
    "\n",
    "You just have to define the forward function, and the backward function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the forward function.\n",
    "\n",
    "The network we will be defining here will contain a `single Linear Layer`.\n",
    "\n",
    "The linear layer contains 2 variables `weights` and `bias`, which is changed by PyTorch so as to make the model perform better on the training data.\n",
    "\n",
    "This simple mathematical model multiplies the images variable x with the weights and then adds the biases.\n",
    "\n",
    "The result is a matrix of shape [num_images, num_classes] because x has shape [num_images, img_size_flat] and weights has shape [img_size_flat, num_classes], so the multiplication of those two matrices is a matrix with shape [num_images, num_classes] and then the biases vector is added to each row of that matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __init__( ) function\n",
    "1. The first variable that must be optimized is called weights and is defined here as a Pytorch variable that must be initialized with zeros and whose shape is `[img_size_flat, num_classes]`, so it is a 2-dimensional tensor (or matrix) with img_size_flat rows and num_classes columns.\n",
    "2. The second variable that must be optimized is called biases and is defined as a 1-dimensional tensor (or vector) of length num_classes.\n",
    "3. Here in the __init__() function both weight and bias Tensors wrapped in as `Parameter`.Parameters are `Tensor` subclasses, that have a very special property when used with Module s - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in `parameters()` iterator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward( ) function\n",
    "1. The forward function will take input of shape `[num_images, img_size_flat]` and multiplies `weight` of shape `[num_images, num_classes]` and the `bias`  is added to final result. We can use torch built in func call `torch.addmm()` for performing the above operation.It is similar to `tf.nn.xw_plus_b` in `Tensorflow`\n",
    "2. The `out` in first line of `forward()` will have the shape `[num_images, num_classes]`\n",
    "3. However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, so we want to normalize them so that each row of the `out` matrix sums to one, and each element is limited between zero and one. This is calculated using the so-called softmax function and the result is stored in `out` it self.\n",
    "\n",
    "```N.B The module `softmax` doesn’t work directly with NLLLoss, which expects the Log to be computed between the Softmax and itself. we will be Using LogSoftmax instead (it’s faster and has better numerical properties).```\n",
    "\n",
    "Softmax takes input matrix and `dim`, A dimension along which Softmax will be computed (so every slice along dim will sum to 1)\n",
    "\n",
    "If you are using softmax in forward function, the you should use Cross Entropy loss for the loss. \n",
    "LINK - https://pytorch.org/docs/stable/torch.html#torch.addmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_weights( )\n",
    "1. This function is used to get the weights of the Network. This could be plotted to understand what the model actually has learned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.weight = Parameter(torch.zeros((784, 10),dtype=torch.float32,requires_grad=True))\n",
    "        self.bias = Parameter(torch.zeros((10),dtype=torch.float32,requires_grad=True))\n",
    "        \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = torch.addmm(self.bias, x, self.weight)\n",
    "        out = F.log_softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train the Network\n",
    "\n",
    "Input:\n",
    "\n",
    "model : model object\n",
    "\n",
    "device : cpu or cuda\n",
    "\n",
    "train_loader : Data loader. Combines a dataset and a sampler, and provides single or multi-process iterators over the dataset\n",
    "\n",
    "\n",
    "optimizer : the function we are going to use for adjusting model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `model.train()`: tells your model that you are training the model. So effectively layers like dropout, batchnorm etc. which behave different on the train and test procedures know what is going on and hence can behave accordingly.\n",
    "2. `for loop` : it will iterate through train_loader and will give you 2 outputs `data` and `target`. The size of `data` and `target` will depend on the `batch_size` that you have provided while creating the `DataLoader` function for `train dataset` . `data` shape `[batch_size,row,columns]`,`target` shape `[batch_size]` \n",
    "3. Here`data` will be of shape `[batch_size,row,columns]` ,we will convert `data` into `[batch_size,row x columns]`  (Flattening the images to fit into Linear layer)\n",
    "4. Moving the the `data` and `target` to devices based on our choice and machine specification. \n",
    "5. By calling `optimizer.zero_grad` we will set Gradient buffers to zero. Else the gradients will get  accumulated to existing gradients.\n",
    "6. Input the `data` to `model` and get outputs, The output will be of shape `[batch_size,num_classes]`\n",
    "7. `Loss function` : A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target . We will be using the negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
    "`nll_loss` : calculates the difference between the `output` to `target` , `output` of shape `[batch_size,num_classes]` and `target` of shape `[batch_size]`  where each value is `0 ≤ targets[i] ≤ num_classes−1`\n",
    "\n",
    "NOTE :\n",
    "MultiClass Classification : We can use have a log softmax layer in the forward function and use NLL_loss. Alternatively you can use Cross Entropy Loss for multi class classification. It has both nn.LogSoftmax() and nn.NLLLoss() in one single class.So you do not need a log softmax layer in your forward function. Code with Cross Entropy loss is available at the end of this notebook.\n",
    "\n",
    "Binary Classification: If you have a binary classification problem, You can use a sigmoide layer in your forward function and use BCELOss (Binary Cross Entropy loss) . Alrenatively you can use BCEWithLogitsLoss. This loss combines a `Sigmoid` layer and the `BCELoss` in one single class. So you do not need a sigmoid layer in your forward function. \n",
    "\n",
    "8. when we call `loss.backward()`, the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has `requires_grad=True` will have their `.grad` Tensor accumulated with the gradient.\n",
    "9. To backpropagate the error all we have to do is to `loss.backward()`\n",
    "10. `optimizer.step()` : performs a parameter update based on the current gradient (stored in .grad attribute of a parameter) and the update rule.\n",
    "\n",
    "LINK : https://pytorch.org/docs/stable/nn.html?highlight=model%20train\n",
    "       https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "       https://pytorch.org/docs/stable/autograd.html\n",
    "       https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,train_loader,optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    #y_true = [] # uncomment these lines if u want to use sklearn's metrics \n",
    "    #y_pred = [] # uncomment these lines if u want to use sklearn's metrics \n",
    "    for data,target in train_loader:\n",
    "         # we have a 28 X 28 image. we are flattening it to \n",
    "        data = torch.reshape(data,(-1,784))\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #set the gradient values to zero at the start of training.\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item() #comment these lines if u want to calculate accuracy without sklearn.\n",
    "        #y_pred.extend(pred.reshape(-1).tolist()) # uncomment these lines if u want to use sklearn's metrics \n",
    "        #y_true.extend(target.reshape(-1).tolist()) # uncomment these lines if u want to use sklearn's metrics \n",
    "    #print(\"Accuracy is\" , accuracy_score(y_true,y_pred)) # uncomment these lines if u want to use sklearn's metrics \n",
    "    print('Training set Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(train_loader.dataset),100. * correct / len(train_loader.dataset))) #comment these lines if u want to calculate accuracy without sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to test the Network\n",
    "- Input:\n",
    "    - model : model object\n",
    "    \n",
    "    - device : `cpu` or `cuda`\n",
    "    \n",
    "    - test_loader : Data loader. Combines a dataset and a sampler, and provides single or multi-process iterators over the                    dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `model.eval()` : tells your model that you are testing the model.So the Regularization Layers like `Dropout` and `BatchNormalization` get disabled. \n",
    "2. The wrapper `with torch.no_grad()` temporarily sets all the requires_grad flag to false. Because we don't need to compute gradients while are getting our inference from the network.This will reduce memory usage and speed up computations.\n",
    "3. The next three line are the same as train function\n",
    "4. we will calculate the test_loss across the complete dataset\n",
    "5. we will also calculate the `accuracy` of model by comparing with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    #y_true = [] # uncomment these lines if u want to use sklearn's metrics \n",
    "    #y_pred = [] # uncomment these lines if u want to use sklearn's metrics \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = torch.reshape(data,(-1,784))\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1) # get the index of the max log-probability\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            \n",
    "            # this is to flatten the tensor, convert to a list and extend it for all the batches\n",
    "            #y_pred.extend(pred.reshape(-1).tolist()) # uncomment these lines if u want to use sklearn's metrics \n",
    "            #y_true.extend(target.reshape(-1).tolist()) # uncomment these lines if u want to use sklearn's metrics \n",
    "    #print(\"Accuracy is\" , accuracy_score(y_true,y_pred)) # uncomment these lines if u want to use sklearn's metrics \n",
    "           \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),\n",
    "        (100. * correct / len(test_loader.dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Device Availabilty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader function for Training Set and Test Set:\n",
    "Data loader combines a dataset and a sampler, and provides single or multi-process iterators over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "train_loader = DataLoader(mnist_train,batch_size=64,shuffle=True,**kwargs)\n",
    "test_loader = DataLoader(mnist_test,batch_size=1024,shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model object is created and Transferred to `device` according to the availabilty of `GPU` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `stochastic gradient descent|(SGD)` optimizer\n",
    "\n",
    "`SGD` takes `model parameters` the we want to optimze and a learning_rate `lr` in which the model parametrs get updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(),lr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters contain the weights and biases that we defined inside our model , So while training the weight and bias will get updated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `epoch` is 10 .So in training the model will get iterated through the complete Training set 10 times .\n",
    "\n",
    "After each epoch we will run `test` and check how well the model is performing on unseen data.\n",
    "\n",
    "If the Training Accuracy is going Up and Testing Accuracy is going down we can say that model is overfitting on the train set. \n",
    "\n",
    "There are Techinques like `EarlyStopping` and usage of validation datset that we will discuss later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Accuracy: 46011/54000 (85%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9115, Accuracy: 8803/10000 (88%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:33, 6329730.67it/s]                             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Accuracy: 47239/54000 (87%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4293, Accuracy: 8205/10000 (82%)\n",
      "\n",
      "Training set Accuracy: 47481/54000 (88%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8409, Accuracy: 8910/10000 (89%)\n",
      "\n",
      "Training set Accuracy: 47826/54000 (89%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8153, Accuracy: 8917/10000 (89%)\n",
      "\n",
      "Training set Accuracy: 47884/54000 (89%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1572, Accuracy: 8517/10000 (85%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "        train(model,device,train_loader,optimizer)\n",
    "        test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE with Cross Entropy Loss :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}\n",
    "train_loader = DataLoader(mnist_train,batch_size=64,shuffle=True,**kwargs)\n",
    "test_loader = DataLoader(mnist_test,batch_size=1024,shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(),lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.weight = Parameter(torch.zeros((784, 10),dtype=torch.float32,requires_grad=True))\n",
    "        self.bias = Parameter(torch.zeros((10),dtype=torch.float32,requires_grad=True))\n",
    "        \n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = torch.addmm(self.bias, x, self.weight)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,train_loader,optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data,target in train_loader:\n",
    "        data = torch.reshape(data,(-1,784))\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # Cross entropy loss combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "        # So we need not have a logsoftmax layer in our forward function.   \n",
    "        loss = criterion(output, target) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim=1)\n",
    "        y_pred.extend(pred.reshape(-1).tolist())\n",
    "        y_true.extend(target.reshape(-1).tolist())\n",
    "    print(\"Accuracy on training set is\" , accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = torch.reshape(data,(-1,784))\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1) # get the index of the max log-probability\n",
    "            y_true.extend(target.reshape(-1).tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "    print(\"Accuracy on test set is\" , accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set is 0.8517962962962963\n",
      "Accuracy on test set is 0.8665\n",
      "Accuracy on training set is 0.8758888888888889\n",
      "Accuracy on test set is 0.8981\n",
      "Accuracy on training set is 0.8800370370370371\n",
      "Accuracy on test set is 0.8916\n",
      "Accuracy on training set is 0.8829444444444444\n",
      "Accuracy on test set is 0.8872\n",
      "Accuracy on training set is 0.8848703703703704\n",
      "Accuracy on test set is 0.8762\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "        train(model,device,train_loader,optimizer)\n",
    "        test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
